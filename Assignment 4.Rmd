---
title: "Assignment 4"
author: "Veronica Rosado"
date: "11/28/2021"
output:
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
    theme: flatly
    code_folding: hide
---

# Introduction

Emil City is looking to more efficiently target home owners who are eligible for a home repair tax credit program. Although the city's Department of Housing and Community Development reaches out to eligible homeowners, only 11% avail of the credit. This project aims to develop a model to identify eligible homeowners who are more likely to take the credit. The findings will help inform the HCD so they could focus their marketing efforts and maximize outcomes. 


```{r setup, include=FALSE}

options(scipen=10000000)
library(tidyverse)
library(kableExtra)
library(viridis)
library(caret)
library(knitr) 
library(pscl)
library(plotROC)
library(pROC)
library(lubridate)
library(gridExtra)
library(htmltools)
library(ggpubr)
library(ggplot2)
library(stargazer)


root.dir = "https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/"
source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")

windowsFonts(font = windowsFont('Franklin Gothic'))

mapTheme <- function(base_size = 10, title_size = 12) {
  theme(
    text = element_text(family = 'font', color = "black"),
    plot.title = element_text(family = 'font', size = title_size,colour = "black"),
    plot.subtitle=element_text(family = 'font', face="italic"),
    plot.caption=element_text(family = 'font', hjust=0),
    axis.ticks = element_blank(),
    panel.background = element_blank(),axis.title = element_blank(),
    axis.text = element_blank(),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(colour = "black", fill=NA, size=.7),
    strip.text.x = element_text(family = 'font', size = 9))
}

mapTheme2 <- function(base_size = 9, title_size = 10) {
  theme(
    text = element_text(family = 'font', color = "black"),
    plot.title = element_text(family = 'font', size = title_size,colour = "black"),
    plot.subtitle = element_text(family = 'font', face="italic"),
    plot.caption=element_text(family = 'font', hjust=0),
    axis.ticks = element_blank(),
    panel.background = element_blank(),axis.title = element_blank(),
    axis.text = element_blank(),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(colour = "black", fill=NA, size=.5),
    strip.text.x = element_text(family = 'font', size = 10),
    legend.text = element_text(family = 'font', size=8),
    legend.title = element_text(family = 'font', size=9),
    legend.background = element_blank(),
    legend.key.size = unit(.3, 'line'))
}

plotTheme <- function(base_size = 10, title_size = 12){
  theme(
    text = element_text(family = 'font', color = "black"),
    plot.title = element_text(family = 'font',
                              size = title_size, colour = "black", hjust = 0.5), 
    plot.subtitle = element_text(family = 'font', face = 'italic',
                                 size = base_size, colour = "black", hjust = 0.5),
    plot.caption = element_text(family = 'font', hjust=0),
    axis.ticks = element_blank(),
    panel.background = element_blank(),
    panel.grid.major = element_line("grey80", size = 0.01),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(colour = "black", fill=NA, size=.5),
    strip.background = element_blank(),
    strip.text = element_text(family = 'font', size=9),
    axis.title = element_text(family = 'font', size=9),
    axis.text = element_text(family = 'font', size=9),
    plot.background = element_blank(),
    legend.background = element_blank(),
    legend.title = element_text(family = 'font', colour = "black", face = "italic"),
    legend.text = element_text(family = 'font', colour = "black", face = "italic"),
    strip.text.x = element_text(family = 'font', size = 9),
    legend.key.size = unit(.3, 'line')
  )
}

plotTheme2 <- function(base_size = 9, title_size = 10){
  theme(
    text = element_text(family = 'font', color = "black"),
    plot.title = element_text(family = 'font',
                              size = title_size, colour = "black", hjust = 0.5), 
    plot.subtitle = element_text(family = 'font', face = 'italic',
                                 size = base_size, colour = "black", hjust = 0.5),
    plot.caption = element_text(family = 'font', hjust=0),
    axis.ticks = element_blank(),
    panel.background = element_blank(),
    panel.grid.major = element_line("grey80", size = 0.01),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(colour = "black", fill=NA, size=.5),
    strip.background = element_blank(),
    strip.text = element_text(family = 'font', size=9),
    axis.title = element_text(family = 'font', size=9),
    axis.text = element_text(family = 'font', size=7),
    axis.text.y = element_text(family = 'font', size=7),
    plot.background = element_blank(),
    legend.background = element_blank(),
    legend.title = element_text(family = 'font', colour = "black", face = "italic", size = 9),
    legend.text = element_text(family = 'font', colour = "black", face = "italic"),
    strip.text.x = element_text(family = 'font', size = 9),
    legend.key.size = unit(.3, 'line')
  )
}

palette5 <- c("#324376", "#586ba4", "#f5dd90", "#ee964b", "#f95738")
palette4 <- c("#113245", "#ed5958", "#f2b531", "#03878f")
palette2 <- c("#113245", "#ed5958")

housing <- read.csv("~/CPLNPennDesign/590-Musa/Musa508-Vero/Public-Policy-Analytics-Landing/DATA/Chapter6/housingSubsidy.csv")

housing <-
  housing %>%
  na.omit()
```


# Exploratory Analysis

Based on HCD's records from previous campaigns, only 451 (11%) homeowners took the credit. These records also include various information on homeowners which we will use to develop a model predicting the homeowner's likelihood of accepting the credit. The variables are divided into three groups - continuous outcomes, binary variables (Yes / No), and multi-category features. 

In Figure 1, some variables have significantly different yes and no outcomes. Individuals are less likely to use the tax credit program if they have been contacted more times `campaign`, more days have passed since they were last contacted from a previous program `pdays`, and if `inflation` is higher. If individuals have been contacted more times before this campaign, they are more likely to use the tax program`previous`.


```{r Continuous, echo=TRUE, message=FALSE, warning=FALSE}

#Continuous- Numeric
housing %>%
  dplyr::select(y,age, unemploy_rate,inflation_rate, spent_on_repairs, campaign, previous, cons.price.idx,cons.conf.idx, pdays) %>%
  gather(Variable, value, -y) %>%
    ggplot(aes(y, value, fill=y)) + 
      geom_bar(position = "dodge", stat = "summary", fun.y = "mean") + 
      facet_wrap(~Variable, scales = "free") +
      scale_fill_manual(values = palette2) +
      labs(x="Used Credit", y="Value",
           title = "Figure 1. Feature associations with the likelihood of taking tax credit",
           subtitle = "(continous outcomes)") +
      theme(legend.position = "none")+
  plotTheme()

```


We also created a distribution plot for these continuous variables. Figure 2 shows that there are variations in credit uptake within certain features. For example, fewer homeowners under 50 years old are taking the credit. At lower inflation rates, more homeowners take the credit, but at higher inflation rates, less homeowners do so.

```{r Uptake vs No Uptake}

housing %>%
    dplyr::select(y, age, campaign, previous, unemploy_rate, cons.price.idx, cons.conf.idx, inflation_rate, pdays, previous, spent_on_repairs, unemploy_rate) %>%
    gather(Variable, value, -y) %>%
    ggplot() + 
    geom_density(aes(value, color=y), fill = "transparent") + 
    facet_wrap(~Variable, scales = "free") +
    scale_color_manual(values = palette2) +
    labs(title = "Figure 2. Feature distributions: uptake vs. no uptake",
         subtitle = "Numeric features") +
  plotTheme()
```


In Figure 3, those who carry a `mortgage`, have `taxLien` against the owner's property, and have a full time residence in Philadelphia `taxbill_in_ph` are more likely to accept tax credit.

```{r Yes or No, echo=TRUE, message=FALSE, warning=FALSE}

# Yes/No
housing %>%
  dplyr::select(y,mortgage, taxbill_in_phl, taxLien) %>%
  gather(Variable, value, -y) %>%
  count(Variable, value, y) %>%
    ggplot(aes(y, n, fill=y)) + 
      geom_bar(position = "dodge", stat = "summary", fun.y = "mean") + 
      facet_wrap(~Variable, scales = "free") +
      scale_fill_manual(values = palette2) +
      labs(x="Used Credit", y="Value", 
           title = "Figure 3. Feature associations with the likelihood of taking tax credit",
           subtitle = "(Yes/No)") +
      theme(legend.position = "none")+
  plotTheme()

```      


For multiple category variables, the likelihood of accepting credit depends on the `education` levels, `marital` status, certain `months` of the year, the type of `job`, mode of `contact`, and `poutcome` of previous marketing campaigns. 


```{r Categorical, echo=TRUE, message=FALSE, warning=FALSE, fig.height=8}

#Categorical
housing %>% 
  dplyr::select(y, job, marital, education, contact, month, day_of_week, poutcome) %>%
  gather(Variable, value, -y) %>%
  count(Variable, value, y) %>%
  ggplot(aes(value, n, fill = y)) +   
    geom_bar(position = "dodge", stat="identity") +
    facet_wrap(~Variable, scales="free") +
    scale_fill_manual(values = palette2) +
    labs(x="Took Credit", y="Count",
         title = "Figure 4. Feature associations with the likelihood of taking tax credit",
         subtitle = "Multiple category features") +
    theme(axis.text.x = element_text(angle=45, hjust=1))+
  plotTheme()

```


# Logistic Regression

## Kitchen sink model

In the kitchen sink model, we included most of the features in HCD's records, except for those that did not have substantially different yes and no outcomes. We also split our data into a 65-35 to test the model. The regression results show that only some of the variables are significant. 

```{r kitchen sink model, echo=TRUE, message=FALSE, warning=FALSE}

set.seed(3456)
trainIndex <- createDataPartition(y = paste(housing$taxLien), p = .65, list = FALSE, times = 1)

housingTrain <- housing[ trainIndex,]
housingTest  <- housing[-trainIndex,]

kitchensink <- glm(y_numeric ~ .,
                   data=housingTrain %>% 
                   dplyr::select(-cons.price.idx, -cons.conf.idx, -y, -spent_on_repairs, -previous, -education), family="binomial" (link="logit"))


stargazer(kitchensink, type = "text", 
          title="Regression Results - Kitchen Sink Model")

#McFadden is 0.23

```


# Distribution of predicted probabilities

The plot below shows the distribution of the predicted probabilities for yes and no outcomes. We see that the 'hump' of predicted probabilities of not taking the credit clusters around 0. For those taking credit, the 'hump'should be closer to 1. This indicates that our kitchen sink model has better predictive power for negative results, but not for positive results.

```{r , echo=FALSE}

testProbs = data.frame(observed = as.factor(housingTest$y_numeric),
                       probs = predict(kitchensink, housingTest, type = 'response'))

ggplot(testProbs, aes(x = probs, fill = as.factor(observed))) +
  geom_density() +
  facet_grid(observed ~ ., labeller = ) +
  scale_fill_manual(values = palette2, name = 'Take credit',
                    labels = c('No', 'Yes')) +
  labs(x = 'Predicted probability of taking credit', 
       y = 'Density of probability',
       title = 'Distribution of predicted probabilities by observed outcome') +
  xlim(0, 1) +
  ylim(0, 23) +
  plotTheme2()


```


# The Final Model: An Improved one

## Feature Engineering

To improve our model, we recategorized some of the variables based on their distribution on the previous model

```{r Feature Eng, echo=TRUE, message=FALSE, warning=FALSE}

# Age Groups         
housing <-
  housing %>%
  mutate(age_cat = case_when(
    age <= 50 ~ "Below 50",
    age > 50  ~ "Above 50"))

# Pdays
housing <-
  housing %>%
  mutate(pdays_cat = case_when(pdays == 999 ~ "Not Contacted",
                             TRUE  ~ "Contacted"))
#Previous
housing <-
  housing %>%
  mutate(previous_cat = case_when(previous == 0 ~ "0",
                               previous == 1 ~ "1" ,
                               previous > 1 ~ "Other"))
#campaign
housing <-
  housing %>%
  mutate(campaign_cat = case_when(
    campaign == 1   ~ "1",
    campaign == 2  ~ "2",
    campaign >= 3  ~ "At least 3"))

# Education
housing <-
  housing %>%
  mutate(education_cat = case_when(
    education == "basic.9y" |education == "basic.6y" | education == "basic.4y" ~ "Less Than HS",
    education == "high.school"  ~ "High School",
    education == "university.degree" |education == "professional.course"  ~ "Higher Education",
    education == "unknown" |education == "illiterate"  ~ "Other"))

#Month
housing <-
  housing %>%
  mutate(month_cat = case_when(
    month == "dec" |month == "mar" | month == "oct" | month == "sep" ~ "Off-peak",
    TRUE ~ "Peak"))

# Employment Status
housing <- 
  housing %>% 
  mutate(job_cat = case_when(job == "student" | job == "unemployed" | job == "retired" ~ "unemployed", TRUE  ~ "employed"))

#Spent on repairs
housing <-
  housing %>%
  mutate(spent_on_repairs_cat = case_when(
    spent_on_repairs <5090    ~ "Under $5090",
    spent_on_repairs > 5170  ~ "Over $5170",
    TRUE ~ "Other"))

#Inflation
housing <-
  housing %>%
  mutate(inflation_rate_cat = case_when(
    inflation_rate <= 3   ~ "Over 3",
    inflation_rate > 3  ~ "Under 3"))

```


Variables that were not found significant were dropped. This is then compared to the kitchen sink model which trains including all variables.

```{r Logit Model, echo=FALSE, message=FALSE, warning=FALSE}
set.seed(3456)

trainIndex2 <- createDataPartition(y = paste(housing$taxLien), p = .65, list = FALSE, times = 1)

housingTrain2 <- housing[ trainIndex2,]
housingTest2  <- housing[-trainIndex2,]


reg1 <- glm(y_numeric ~ .,
                   data=housingTrain2 %>% 
                   dplyr::select(-cons.price.idx, -cons.conf.idx, -y, -spent_on_repairs, -previous), 
            family="binomial" (link="logit"))


stargazer(reg1, type = "text", 
          title="Regression Results - Final Model")

```


According to general rules of thumb for McFadden R2 interpretations, a value of 0.20+ indicates that the model is well fit. Here we can see that our model scored at 0.23, meaning that it is a reliable fit for us to derive conclusions from. Now, this alone does not describe the range of probabilities for churn or no churn. For that, the next section runs a test on the probabilities' distribution. 


# Distribution of predicted probabilities

The plot below shows the distribution of predicted probabilities for churn(1) and no churn(0). The model is predicting that more people may NOT take the credit than the people that would.

```{r PredProbs 2, echo=TRUE, message=FALSE, warning=FALSE}

testProbs2 = data.frame(observed = as.factor(housingTest2$y_numeric),
                       probs = predict(kitchensink, housingTest2, type = 'response'))

ggplot(testProbs2, aes(x = probs, fill = as.factor(observed))) +
  geom_density() +
  facet_grid(observed ~ ., labeller = ) +
  scale_fill_manual(values = palette2, name = 'Take credit',
                    labels = c('No', 'Yes')) +
  labs(x = 'Predicted probability of taking credit', 
       y = 'Density of probability',
       title = 'Distribution of predicted probabilities by observed outcome, Test Set 2') +
  xlim(0, 1) +
  ylim(0, 23) +
  plotTheme2()

```

# Model Evaluation

## ROC curve

The ROC curve allows us to split the predicted outcomes in various thresholds to better understand the performance of the model in predicting either churn or no churn better. In here, we use a confusion matrix that helps identify the question.  

Confusion Matrix Summary:

Prediction show that there were:

**30** true positives, correctly predicted to take the credit; **112** false positives, incorrectly predicted to take the credit (potential loss of marketing $); **1271** true negatives, correctly predicted to NOT take the credit; and **28** false negatives, incorrectly predicted to NOT take the credit (people that took it in the end)


Accuracy, Specificity and Sensitivity:

Accuracy : 0.9028           
Sensitivity : 0.21127          
Specificity : 0.97844


```{r ROC Crv, echo=TRUE, message=FALSE, warning=FALSE}

testProbs2 <- 
  testProbs2 %>%
  mutate(predOutcome  = as.factor(ifelse(testProbs2$probs > 0.5 , 1, 0)))

caret::confusionMatrix(testProbs2$predOutcome, testProbs2$observed,
                       positive = "1")

ggplot(testProbs2, aes(d = as.numeric(testProbs2$observed), m = probs)) +
  geom_roc(n.cuts = 50, labels = FALSE, colour = "#ed5958") +
  style_roc(theme = theme_grey) +
  geom_abline(slope = 1, intercept = 0, size = 1.5, color = 'grey') +
  labs(title = "ROC Curve - Churn Model") +
  plotTheme2()

pROC::auc(testProbs2$observed, testProbs2$probs)

```

The ROC curve shows the trade-off between sensitivity and specificity. At 0.75, the area under the curve of the new model is slightly lower compared to the kitchen sink model. See below...


Kitchen Sink vs Final Model ROC Plots

```{r echo=TRUE, message=FALSE, warning=FALSE}

a1 <- ggplot(testProbs, aes(d = as.numeric(testProbs$observed), m = probs)) +
  geom_roc(n.cuts = 50, labels = FALSE, colour = "#ed5958") +
  style_roc(theme = theme_grey) +
  geom_abline(slope = 1, intercept = 0, size = 1.5, color = 'grey') +
  labs(title = "ROC Curve - Kitchen Sink") +
  plotTheme()

a2 <- ggplot(testProbs2, aes(d = as.numeric(testProbs2$observed), m = probs)) +
  geom_roc(n.cuts = 50, labels = FALSE, colour = "#ed5958") +
  style_roc(theme = theme_grey) +
  geom_abline(slope = 1, intercept = 0, size = 1.5, color = 'grey') +
  labs(title = "ROC Curve - Final Model") +
  plotTheme()

ggarrange(a1, a2)

```


## Cross Validation

The Cross validation part helps to measure generalizability to new data. It splits the data into to sets and runs 100 k-folds over the data, outcoming predicted probabilities (classProbs). 

```{r Cross V, echo=TRUE, message=FALSE, warning=FALSE}

ctrl <- trainControl(method = "cv", number = 100, classProbs=TRUE, summaryFunction=twoClassSummary)

cvFit <- train(y ~ .,
                  data = housing %>% 
                    na.omit() %>%
                    dplyr::select(-cons.price.idx, -cons.conf.idx, -y_numeric, -spent_on_repairs, 
                                  -previous),
                method="glm", family="binomial",
                metric="ROC", trControl = ctrl) 


dplyr::select(cvFit$resample, -Resample) %>%
   gather(metric, value) %>%
   left_join(gather(cvFit$results[2:4], metric, mean)) %>%
   ggplot(aes(value)) + 
   geom_histogram(bins=35, fill = "#113245") +
   facet_wrap(~metric) +
   geom_vline(aes(xintercept = mean), colour = "#ed5958", linetype = 3, size = 1) +
   scale_x_continuous(limits = c(0, 1)) +
   labs(x="Goodness of Fit", y="Count", title="CV Goodness of Fit Metrics",
        subtitle = "Across-fold mean reprented as dotted lines")+
   plotTheme2()

```


## Comparing Improved and Baseline Models

Compared to the kitchen sink model, the featured engineered model improved accuracy, sensitivity and specificity by a little. While this may not be substantial for this case study, for others it could be. 

## Confusion Matrix for Kitchen Sink (Baseline)

Predictions:

• 33 true positives
• 109 false positives
• 1268 true negatives
• 31 false negatives

The baseline model points a higher prediction for true positives, but a lower number of instances for the group that has been incorrectly predicted to take the credit (false positives). 

```{r ROC Kitchen Sink CM, echo=TRUE, message=FALSE, warning=FALSE}

testProbs <- 
  testProbs %>%
  mutate(predOutcome  = as.factor(ifelse(testProbs$probs > 0.5 , 1, 0)))

caret::confusionMatrix(testProbs$predOutcome, testProbs$observed,
                       positive = "1")

ggplot(testProbs, aes(d = as.numeric(testProbs$observed), m = probs)) +
  geom_roc(n.cuts = 50, labels = FALSE, colour = "#ed5958") +
  style_roc(theme = theme_grey) +
  geom_abline(slope = 1, intercept = 0, size = 1.5, color = 'grey') +
  labs(title = "ROC Curve for Baseline Model - churn model") +
  plotTheme2()

```

```{r pROC, message=FALSE, warning=FALSE, include=FALSE}

pROC::auc(testProbs$observed, testProbs$probs)
```


Small multiple plot, Goodness of Fit for the baseline model

```{r ROC Kitchen Sink Comparison, echo=TRUE, message=FALSE, warning=FALSE}

ctrl <- trainControl(method = "cv", number = 100, classProbs=TRUE, summaryFunction=twoClassSummary)


cvFit_Ks <- train(y ~ .,
                  data = housingTrain %>% 
                    na.omit() %>%
                    dplyr::select(-cons.price.idx, -cons.conf.idx, -y_numeric, -spent_on_repairs, 
                                  -previous, -education),
                method="glm", family="binomial",
                metric="ROC", trControl = ctrl) 


dplyr::select(cvFit_Ks$resample, -Resample) %>%
  gather(metric, value) %>%
  left_join(gather(cvFit_Ks$results[2:4], metric, mean)) %>%
  ggplot(aes(value)) + 
    geom_histogram(bins=35, fill = "#FF006A") +
    facet_wrap(~metric) +
    geom_vline(aes(xintercept = mean), colour = "#981FAC", linetype = 3, size = 1) +
    scale_x_continuous(limits = c(0, 1)) +
    labs(x="Goodness of Fit", y="Count", title="CV Goodness of Fit Metrics for Baseline Model",
         subtitle = "Across-fold mean reprented as dotted lines") +
    plotTheme()

```


# Cross Validation:

## Cost Benefit Analysis

We developed a cost-benefit analysis that would help the Department of Housing and Community Development allocate its resources more efficiently. The following assumptions were made about the marketing campaign:

• $2,850 HCD allocation per homeowner

• 25% of contacted eligible homeowners take the credit

• $5000 credit cost per homeowner

• Houses that transacted after taking the credit sold with $10,000 premium


Thresholds for cross benefit calculations are described below:

**True Negative Revenue** - Predicted correctly homeowner would not take the credit, no marketing resources were allocated, and no credit was allocated.
Count*0

**True Positive Revenue** - Predicted correctly homeowner would take the credit; allocated the marketing resources, and 25% took the credit.
Count*(-2850)-[(Count*.25)*-5000]

**False Negative Revenue** - We predicted that a homeowner would not take the credit but they did. These are likely homeowners who signed up for reasons unrelated to the marketing campaign. Thus, we ‘0 out’ this category, assuming the cost/benefit of this is $0.
Count*0

**False Positive Revenue** - Predicted incorrectly homeowner would take the credit; allocated marketing resources; no credit allocated.
Count*-2850

```{r Cost Benfit, message=FALSE, warning=FALSE, , echo=FALSE}

cost_benefit_table <- # Check math
   testProbs2 %>%
      count(predOutcome, observed) %>%
      summarize(True_Negative = sum(n[predOutcome==0 & observed==0]),
                True_Positive = sum(n[predOutcome==1 & observed==1]),
                False_Negative = sum(n[predOutcome==0 & observed==1]),
                False_Positive = sum(n[predOutcome==1 & observed==0])) %>%
       gather(Variable, Count) %>%
       mutate(Revenue =
               case_when(Variable == "True_Negative"  ~ Count * 0,  
                         Variable == "True_Positive"  ~ ((Count * -2850) - ((Count * .25) * -5000)),  
                         Variable == "False_Negative" ~ Count * 0,
                         Variable == "False_Positive" ~ (Count * -2850))) %>%
    bind_cols(data.frame(Description = c(
              "Predicted correctly homeowner would not take the credit, no marketing resources
              were allocated, and no
              credit was allocated.",
              "Predicted correctly homeowner would take the credit; allocated the marketing 
              resources, and 25% took
              the credit.", #25% take the 5000
              "We predicted that a homeowner would not take the credit but they did.",
              "Predicted incorrectly homeowner would take the credit; allocated marketing 
              resources; no credit
              allocated.")))

cost_benefit_table %>%
  kable(caption = "Table 3: Cost/Benefit Table") %>%
  kable_styling()


caret::confusionMatrix(testProbs2$predOutcome, testProbs$observed, 
                       positive = "1")

```

# Optimizing Cost/Benefit Relationship

Ideally, the ‘optimal’ threshold is the one that returns the greatest cost/benefit. In this section, a function is created to iteratively loop through each threshold, calculate confusion metrics, and total the revenue for each. The results are then visualized for each scenario. At a lower threshold, we see the costs associated with the false positives, which eventually flattens the ~0.65 mark.

```{r Threshold, echo=TRUE, message=FALSE, warning=FALSE}

iterateThresholds.1 <- function(data) {
  x = .01
  all_prediction <- data.frame()
  while (x <= 1) {
  this_prediction <-
      testProbs %>%
      mutate(predOutcome = ifelse(probs > x, 1, 0)) %>%
      count(predOutcome, observed) %>%
      summarize(True_Negative = sum(n[predOutcome==0 & observed==0]),
                True_Positive = sum(n[predOutcome==1 & observed==1]),
                False_Negative = sum(n[predOutcome==0 & observed==1]),
                False_Positive = sum(n[predOutcome==1 & observed==0])) %>%
     gather(Variable, Count) %>%
     mutate(Revenue =
               ifelse(Variable == "True_Negative", Count * 0,
               ifelse(Variable == "True_Positive",((.35 - .1) * Count),
               ifelse(Variable == "False_Negative", (-0.35) * Count,
               ifelse(Variable == "False_Positive", (-0.1) * Count, 0)))),
            Threshold = x)
  all_prediction <- rbind(all_prediction, this_prediction)
  x <- x + .01
  }
return(all_prediction)
}


whichThreshold <- iterateThresholds.1(testProbs2)

whichThreshold_revenue <- 
whichThreshold %>% 
    group_by(Threshold) %>% 
    summarize(Revenue = sum(Revenue))

whichThreshold %>%
  ggplot(.,aes(Threshold, Revenue, colour = Variable)) +
  geom_point() +
  scale_colour_manual(values = palette5[c(5, 1:3)]) +    
  labs(title = "Figure 9: Revenue by Confusion Matrix Type and Threshold",
       y = "Benefit") +
  plotTheme() +
  guides(color=guide_legend(title = "Confusion Matrix")) 


```


## Plot of Threshold as a Function of Revenue and Count of Credits

This shows thresholds as function of total revenue and count of people who took the credit. The bigger the threshold, the lower the revenues. As count of cedits increase, so does the threshold. 

```{r Small Multiple Plots, echo=TRUE, message=FALSE, warning=FALSE, fig.height=8}

whichThreshold_revenue <- 
  whichThreshold %>% 
  mutate(TookCredit = ifelse(Variable == "True_Positive", (Count * .25),
                         ifelse(Variable == "False_Negative", Count, 0))) %>%
  group_by(Threshold) %>% 
  summarize(Total_Revenue = sum(Revenue), Total_Count_Of_Credits = sum(TookCredit))

#Plot
grid.arrange(ncol = 1,
             ggplot(whichThreshold_revenue) + 
               geom_line(aes(x = Threshold, y = Total_Revenue)) +
               geom_vline(xintercept =  pull(arrange(whichThreshold_revenue, -Total_Revenue)[1,1])) +
               labs(title = "Figure 10: Total Revenues By Threshold",
                    subtitle = "Vertical Line Denotes Optimal Threshold"),
             ggplot(whichThreshold_revenue) + 
               geom_line(aes(x = Threshold, y = Total_Count_Of_Credits))+
               geom_vline(xintercept =  pull(arrange(whichThreshold_revenue, -Total_Count_Of_Credits)[1,1])) +
               labs(title = "Figure 11: Total Count of Credits By Threshold",
                    subtitle = "Vertical Line Denotes Optimal Threshold"))

whichThreshold_revenue %>%
  kable()%>%
  kable_styling()

```

```{r Optimal Threshold, echo=TRUE, message=FALSE, warning=FALSE}

optimalthreshold <-
  whichThreshold_revenue %>%
  dplyr::select(Threshold, Total_Revenue, Total_Count_Of_Credits)

optimalthreshold_table <-
  whichThreshold_revenue %>%
  dplyr::select(Threshold, Total_Revenue, Total_Count_Of_Credits)

optimalthreshold_table <-
  optimalthreshold %>%
  filter(row(optimalthreshold) == c(25, 50))

kable(optimalthreshold_table,
       caption = "Cost Benefit Table") %>% kable_styling()
```


# Conclusion

Predicting probability of tax credit churn and no churn is not an easy task. However our model  

Our model does fairly well at identifying homeowners who were not going to take the credit, which could help HCD save resources by not allocating funds for marketing and information sessions to a group of people who would never accept the credit anyway. However, the model is not the best for identifying those who would take the credit (True Positives). Perhaps adding other features, such as characteristics of homes, location of homes, could improve our model. Additionally, HCD could benefit as well from doing survey work throughout the community as a support for characteristics to help define groups that are likely to accept the credit.  




