---
title: "Assignment 4"
author: "Veronica Rosado"
date: "11/14/2021"
output:
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
    theme: flatly
    code_folding: hide
---

# Introduction

Emil City is looking to more efficiently target home owners who are eligible for a home repair tax credit program. Although the city's Department of Housing and Community Development reaches out to eligible homeowners, only 11% avail of the credit. This project aims to develop a model to identify eligible homeowners who are more likely to take the credit. The findings will help inform the HCD so they could focus their marketing efforts and maximize outcomes. 


```{r setup, include=FALSE}

options(scipen=10000000)
library(tidyverse)
library(kableExtra)
library(viridis)
library(caret)
library(knitr) 
library(pscl)
library(plotROC)
library(pROC)
library(lubridate)
library(gridExtra)
library(htmltools)

root.dir = "https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/"
source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")

windowsFonts(font = windowsFont('Franklin Gothic'))

mapTheme <- function(base_size = 10, title_size = 12) {
  theme(
    text = element_text(family = 'font', color = "black"),
    plot.title = element_text(family = 'font', size = title_size,colour = "black"),
    plot.subtitle=element_text(family = 'font', face="italic"),
    plot.caption=element_text(family = 'font', hjust=0),
    axis.ticks = element_blank(),
    panel.background = element_blank(),axis.title = element_blank(),
    axis.text = element_blank(),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(colour = "black", fill=NA, size=.7),
    strip.text.x = element_text(family = 'font', size = 9))
}

mapTheme2 <- function(base_size = 9, title_size = 10) {
  theme(
    text = element_text(family = 'font', color = "black"),
    plot.title = element_text(family = 'font', size = title_size,colour = "black"),
    plot.subtitle = element_text(family = 'font', face="italic"),
    plot.caption=element_text(family = 'font', hjust=0),
    axis.ticks = element_blank(),
    panel.background = element_blank(),axis.title = element_blank(),
    axis.text = element_blank(),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(colour = "black", fill=NA, size=.5),
    strip.text.x = element_text(family = 'font', size = 10),
    legend.text = element_text(family = 'font', size=8),
    legend.title = element_text(family = 'font', size=9),
    legend.background = element_blank(),
    legend.key.size = unit(.3, 'line'))
}

plotTheme <- function(base_size = 10, title_size = 12){
  theme(
    text = element_text(family = 'font', color = "black"),
    plot.title = element_text(family = 'font',
                              size = title_size, colour = "black", hjust = 0.5), 
    plot.subtitle = element_text(family = 'font', face = 'italic',
                                 size = base_size, colour = "black", hjust = 0.5),
    plot.caption = element_text(family = 'font', hjust=0),
    axis.ticks = element_blank(),
    panel.background = element_blank(),
    panel.grid.major = element_line("grey80", size = 0.01),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(colour = "black", fill=NA, size=.5),
    strip.background = element_blank(),
    strip.text = element_text(family = 'font', size=9),
    axis.title = element_text(family = 'font', size=9),
    axis.text = element_text(family = 'font', size=9),
    plot.background = element_blank(),
    legend.background = element_blank(),
    legend.title = element_text(family = 'font', colour = "black", face = "italic"),
    legend.text = element_text(family = 'font', colour = "black", face = "italic"),
    strip.text.x = element_text(family = 'font', size = 9),
    legend.key.size = unit(.3, 'line')
  )
}

plotTheme2 <- function(base_size = 9, title_size = 10){
  theme(
    text = element_text(family = 'font', color = "black"),
    plot.title = element_text(family = 'font',
                              size = title_size, colour = "black", hjust = 0.5), 
    plot.subtitle = element_text(family = 'font', face = 'italic',
                                 size = base_size, colour = "black", hjust = 0.5),
    plot.caption = element_text(family = 'font', hjust=0),
    axis.ticks = element_blank(),
    panel.background = element_blank(),
    panel.grid.major = element_line("grey80", size = 0.01),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(colour = "black", fill=NA, size=.5),
    strip.background = element_blank(),
    strip.text = element_text(family = 'font', size=9),
    axis.title = element_text(family = 'font', size=9),
    axis.text = element_text(family = 'font', size=7),
    axis.text.y = element_text(family = 'font', size=7),
    plot.background = element_blank(),
    legend.background = element_blank(),
    legend.title = element_text(family = 'font', colour = "black", face = "italic", size = 9),
    legend.text = element_text(family = 'font', colour = "black", face = "italic"),
    strip.text.x = element_text(family = 'font', size = 9),
    legend.key.size = unit(.3, 'line')
  )
}

palette5 <- c("#324376", "#586ba4", "#f5dd90", "#ee964b", "#f95738")
palette4 <- c("#113245", "#ed5958", "#f2b531", "#03878f")
palette2 <- c("#113245", "#ed5958")

housing <- read.csv("~/CPLNPennDesign/590-Musa/Musa508-Vero/Public-Policy-Analytics-Landing/DATA/Chapter6/housingSubsidy.csv")

housing <-
  housing %>%
  na.omit()
```

#Exploratory Analysis

Based on HCD's records from previous campaigns, only 451 (11%) homeowners took the credit. These records also include various information on homeowners which we will use to develop a model predicting the homeowner's likelihood of accepting the credit. The variables are divided into three groups - continuous outcomes, binary variables (Yes / No), and multi-category features. 

In Figure 1, some variables have significantly different yes and no outcomes. Individuals are less likely to use the tax credit program if they have been contacted more times `campaign`, more days have passed since they were last contacted from a previous program `pdays`, and if `inflation` is higher. If individuals have been contacted more times before this campaign, they are more likely to use the tax program`previous`.


```{r Continuous, echo=TRUE, message=FALSE, warning=FALSE}

#Continuous- Numeric
housing %>%
  dplyr::select(y,age, unemploy_rate,inflation_rate, spent_on_repairs, campaign, previous, cons.price.idx,cons.conf.idx, pdays) %>%
  gather(Variable, value, -y) %>%
    ggplot(aes(y, value, fill=y)) + 
      geom_bar(position = "dodge", stat = "summary", fun.y = "mean") + 
      facet_wrap(~Variable, scales = "free") +
      scale_fill_manual(values = palette2) +
      labs(x="Used Credit", y="Value",
           title = "Figure 1. Feature associations with the likelihood of taking tax credit",
           subtitle = "(continous outcomes)") +
      theme(legend.position = "none")+
  plotTheme()

```

We also created a distribution plot for these continuous variables. Figure 2 shows that there are variations in credit uptake within certain features. For example, fewer homeowners under 50 years old are taking the credit. At lower inflation rates, more homeowners take the credit, but at higher inflation rates, less homeowners do so.

```{r Uptake vs No Uptake}

housing %>%
    dplyr::select(y, age, campaign, previous, unemploy_rate, cons.price.idx, cons.conf.idx, inflation_rate, pdays, previous, spent_on_repairs, unemploy_rate) %>%
    gather(Variable, value, -y) %>%
    ggplot() + 
    geom_density(aes(value, color=y), fill = "transparent") + 
    facet_wrap(~Variable, scales = "free") +
    scale_color_manual(values = palette2) +
    labs(title = "Figure 2. Feature distributions: uptake vs. no uptake",
         subtitle = "Numeric features") +
  plotTheme()
```

In Figure 3, those who carry a `mortgage`, have `taxLien` against the owner's property, and have a full time residence in Philadelphia `taxbill_in_ph` are more likely to accept tax credit.

```{r Yes or No, echo=TRUE, message=FALSE, warning=FALSE}

# Yes/No
housing %>%
  dplyr::select(y,mortgage, taxbill_in_phl, taxLien) %>%
  gather(Variable, value, -y) %>%
  count(Variable, value, y) %>%
    ggplot(aes(y, n, fill=y)) + 
      geom_bar(position = "dodge", stat = "summary", fun.y = "mean") + 
      facet_wrap(~Variable, scales = "free") +
      scale_fill_manual(values = palette2) +
      labs(x="Used Credit", y="Value", 
           title = "Figure 3. Feature associations with the likelihood of taking tax credit",
           subtitle = "(Yes/No)") +
      theme(legend.position = "none")+
  plotTheme()

```      


For multiple category variables, the likelihood of accepting credit depends on the `education` levels, `marital` status, certain `months` of the year, the type of `job`, mode of `contact`, and `poutcome` of previous marketing campaigns. 


```{r Categorical, echo=TRUE, message=FALSE, warning=FALSE, fig.height=8}

#Categorical
housing %>% 
  dplyr::select(y, job, marital, education, contact, month, day_of_week, poutcome) %>%
  gather(Variable, value, -y) %>%
  count(Variable, value, y) %>%
  ggplot(aes(value, n, fill = y)) +   
    geom_bar(position = "dodge", stat="identity") +
    facet_wrap(~Variable, scales="free") +
    scale_fill_manual(values = palette2) +
    labs(x="Took Credit", y="Count",
         title = "Figure 4. Feature associations with the likelihood of taking tax credit",
         subtitle = "Multiple category features") +
    theme(axis.text.x = element_text(angle=45, hjust=1))+
  plotTheme()

```

# Logistic Regression

## Building a kitchen sink model

In the kitchen sink model, we included most of the features in HCD's records, except for those that did not have substantially different yes and no outcomes. We also split our data into a 65-35 to test the model. The regression results show that only some of the variables are significant. 


```{r kitchen sink model, echo=TRUE, message=FALSE, warning=FALSE}

set.seed(3456)
trainIndex <- createDataPartition(y = paste(housing$taxLien), p = .65, list = FALSE, times = 1)

housingTrain <- housing[ trainIndex,]
housingTest  <- housing[-trainIndex,]

kitchensink <- glm(y_numeric ~ .,
                   data=housingTrain %>% 
                   dplyr::select(-cons.price.idx, -cons.conf.idx, -y, -spent_on_repairs, -previous, -education), family="binomial" (link="logit"))

summary(kitchensink)

pR2(kitchensink) %>%
  kable(Caption = "Psuedo R Squared") %>%
  kable_styling() #McFadden is 0.23

```


# Distribution of predicted probabilities

Figure 5 below shows the distribution of the predicted probabilities for yes and no outcomes. We see that the 'hump' of predicted probabilities of not taking the credit clusters around 0. For those taking credit, the 'hump'should be closer to 1. This indicates that our kitchen sink model has better predictive power for negative results, but not for positive results.

```{r , echo=FALSE}

testProbs = data.frame(observed = as.factor(housingTest$y_numeric),
                       probs = predict(kitchensink, housingTest, type = 'response'))


ggplot(testProbs, aes(x = probs, fill = as.factor(observed))) +
  geom_density() +
  facet_grid(observed ~ ., labeller = ) +
  scale_fill_manual(values = palette2, name = 'Take credit',
                    labels = c('No', 'Yes')) +
  labs(x = 'Predicted probability of taking credit', 
       y = 'Density of probability',
       title = 'Distribution of predicted probabilities by observed outcome') +
  xlim(0, 1) +
  ylim(0, 23) +
  plotTheme2()

```

# Feature Engineering

To improve our model, we feature recategorized some of the variables based on their distributions. 

```{r Feature Eng}

# Age Groups         
housing <-
  housing %>%
  mutate(age_cat = case_when(
    age <= 50 ~ "Below 50",
    age > 50  ~ "Above 50"))

# Pdays
housing <-
  housing %>%
  mutate(pdays_cat = case_when(pdays == 999 ~ "Not Contacted",
                             TRUE  ~ "Contacted"))
#Previous
housing <-
  housing %>%
  mutate(previous_cat = case_when(previous == 0 ~ "0",
                               previous == 1 ~ "1" ,
                               previous > 1 ~ "Other"))
#campaign
housing <-
  housing %>%
  mutate(campaign_cat = case_when(
    campaign == 1   ~ "1",
    campaign == 2  ~ "2",
    campaign >= 3  ~ "At least 3"))

# Education
housing <-
  housing %>%
  mutate(education_cat = case_when(
    education == "basic.9y" |education == "basic.6y" | education == "basic.4y" ~ "Less Than HS",
    education == "high.school"  ~ "High School",
    education == "university.degree" |education == "professional.course"  ~ "Higher Education",
    education == "unknown" |education == "illiterate"  ~ "Other"))

#Month
housing <-
  housing %>%
  mutate(month_cat = case_when(
    month == "dec" |month == "mar" | month == "oct" | month == "sep" ~ "Off-peak",
    TRUE ~ "Peak"))

# Employment Status
housing <- 
  housing %>% 
  mutate(job_cat = case_when(job == "student" | job == "unemployed" | job == "retired" ~ "unemployed", TRUE  ~ "employed"))

#Spent on repairs
housing <-
  housing %>%
  mutate(spent_on_repairs_cat = case_when(
    spent_on_repairs <5090    ~ "Under $5090",
    spent_on_repairs > 5170  ~ "Over $5170",
    TRUE ~ "Other"))

#Inflation
housing <-
  housing %>%
  mutate(inflation_rate_cat = case_when(
    inflation_rate <= 3   ~ "Over 3",
    inflation_rate > 3  ~ "Under 3"))

```

# Final Logit Model: The Improved one

Variables that are not significant will not be included in the final model, some variables will also be .

```{r Logit Model}

set.seed(3456)
trainIndex2 <- createDataPartition(y = paste(housing$taxLien), p = .65, list = FALSE, times = 1)

housingTrain2 <- housing[ trainIndex2,]
housingTest2  <- housing[-trainIndex2,]


reg1 <- glm(y_numeric ~ .,
                   data=housingTrain2 %>% 
                   dplyr::select(-cons.price.idx, -cons.conf.idx, -y, -spent_on_repairs, -previous), 
            family="binomial" (link="logit"))


summary(reg1)

pR2(reg1) %>%
  kable() %>%
  kable_styling()  #McFadden 0.229

```

# Distribution of predicted probabilities

The plot below shows the distribution of predicted probabilities for churn(1) and no churn(0). The model is predicting that more people may not take the credit than the people that would. 

```{r Pred Probs, echo=FALSE}

testProbs2 = data.frame(observed = as.factor(housingTest2$y_numeric),
                       probs = predict(reg1, housingTest2, type = 'response'))

ggplot(testProbs2, aes(x = probs, fill = as.factor(observed))) +
  geom_density() +
  facet_grid(observed ~ ., labeller = ) +
  scale_fill_manual(values = palette2, name = 'Take credit',
                    labels = c('No', 'Yes')) +
  labs(x = 'Predicted probability of taking credit', 
       y = 'Density of probability',
       title = 'Distribution of predicted probabilities by observed outcome') +
  xlim(0, 1) +
  ylim(0, 23) +
  plotTheme2()

```


## ROC curve

The ROC curve allows us to split the predicted outcomes in various thresholds to better understand the performance of the model in predicting either churn or no churn better. In here, we use a confucsion matrix that helps identify the question.  

Confusion Matrix Summary:
Prediction    0    1
         0 1271  112
         1   28   30
         
Results show that there were:
30 true positives, correctly predicted to take the credit
112 false positives, incorrectly predicted to take the credit (potential loss of marketing $)
1271 true negatives, correctly predicted to NOT take the credit
28 false negatives, incorrectly predicted to NOT take the credit (people that took it in the end)

Accuracy, Specificity and Sensitivity:

Accuracy : 0.9028           
Sensitivity : 0.21127          
Specificity : 0.97844


```{r ROC Crv, echo=FALSE}

testProbs2 <- 
  testProbs2 %>%
  mutate(predOutcome  = as.factor(ifelse(testProbs2$probs > 0.5 , 1, 0)))

caret::confusionMatrix(testProbs2$predOutcome, testProbs2$observed,
                       positive = "1")

ggplot(testProbs2, aes(d = as.numeric(testProbs2$observed), m = probs)) +
  geom_roc(n.cuts = 50, labels = FALSE, colour = "#ed5958") +
  style_roc(theme = theme_grey) +
  geom_abline(slope = 1, intercept = 0, size = 1.5, color = 'grey') +
  labs(title = "ROC Curve - churn model") +
  plotTheme2()

#pROC::auc(testProbs2$observed, testProbs2$probs)

```

#Cross Validation

The Cross validation part helps to  measure generalizability to new data. It splits the data into to sets and runs 100 k-folds over the data, outcoming predicted probabilities (classProbs). 

```{r Cross V, echo=TRUE, message=FALSE, warning=FALSE}

ctrl <- trainControl(method = "cv", number = 100, classProbs=TRUE, summaryFunction=twoClassSummary)

cvFit <- train(y ~ .,
                  data = housing %>% 
                    na.omit() %>%
                    dplyr::select(-cons.price.idx, -cons.conf.idx, -y_numeric, -spent_on_repairs, 
                                  -previous),
                method="glm", family="binomial",
                metric="ROC", trControl = ctrl) 


dplyr::select(cvFit$resample, -Resample) %>%
   gather(metric, value) %>%
   left_join(gather(cvFit$results[2:4], metric, mean)) %>%
   ggplot(aes(value)) + 
   geom_histogram(bins=35, fill = "#113245") +
   facet_wrap(~metric) +
   geom_vline(aes(xintercept = mean), colour = "#ed5958", linetype = 3, size = 1) +
   scale_x_continuous(limits = c(0, 1)) +
   labs(x="Goodness of Fit", y="Count", title="Figure X: CV Goodness of Fit Metrics",
        subtitle = "Across-fold mean reprented as dotted lines")+
   plotTheme2()

```


# Comparing Improved and Baseline Models

Compared to the kitchen sink model, the featured engineered model improved accuracy, sensitivity and specificity by a little. While this may not be substantial for this case study, for others it could be. 

## Confusion Matrix for Kitchen Sink (Base)

Prediction    0    1
         0 1268  109
         1   31   33

33 true positives
109 false positives
1268 true negatives
31 false negatives

The baseline model points a higher prediction for true positives, but a lower number of instances for the group that has been incorrectly predicted to take the credit (false positives). 

```{r ROC Kitchen Sink CM, echo=TRUE, message=FALSE, warning=FALSE}

testProbs <- 
  testProbs %>%
  mutate(predOutcome  = as.factor(ifelse(testProbs$probs > 0.5 , 1, 0)))

caret::confusionMatrix(testProbs$predOutcome, testProbs$observed,
                       positive = "1")

ggplot(testProbs, aes(d = as.numeric(testProbs$observed), m = probs)) +
  geom_roc(n.cuts = 50, labels = FALSE, colour = "#ed5958") +
  style_roc(theme = theme_grey) +
  geom_abline(slope = 1, intercept = 0, size = 1.5, color = 'grey') +
  labs(title = "ROC Curve for Baseline Model - churn model") +
  plotTheme2()

```

```{r pROC, message=FALSE, warning=FALSE, include=FALSE}

pROC::auc(testProbs$observed, testProbs$probs)
```


Small multiple plot, Goodness of Fit for the baseline model

```{r ROC Kitchen Sink Comparison, echo=TRUE, message=FALSE, warning=FALSE}

ctrl <- trainControl(method = "cv", number = 100, classProbs=TRUE, summaryFunction=twoClassSummary)


cvFit_Ks <- train(y ~ .,
                  data = housingTrain %>% 
                    na.omit() %>%
                    dplyr::select(-cons.price.idx, -cons.conf.idx, -y_numeric, -spent_on_repairs, 
                                  -previous, -education),
                method="glm", family="binomial",
                metric="ROC", trControl = ctrl) 


dplyr::select(cvFit_Ks$resample, -Resample) %>%
  gather(metric, value) %>%
  left_join(gather(cvFit_Ks$results[2:4], metric, mean)) %>%
  ggplot(aes(value)) + 
    geom_histogram(bins=35, fill = "#FF006A") +
    facet_wrap(~metric) +
    geom_vline(aes(xintercept = mean), colour = "#981FAC", linetype = 3, size = 1) +
    scale_x_continuous(limits = c(0, 1)) +
    labs(x="Goodness of Fit", y="Count", title="CV Goodness of Fit Metrics for Baseline Model",
         subtitle = "Across-fold mean reprented as dotted lines") +
    plotTheme()

```


# Cross Validation:

## Cost Benefit Analysis

Assumptions:
$2,850 HCD allocation per homeowner
25% of contacted eligible homeowners take the credit
$5000 credit cost per homeowner
Houses that transacted after taking the credit sold with $10,000 premium

True Negative Revenue - Predicted correctly homeowner would not take the credit, no marketing resources were allocated, and no credit was allocated.
Count*0

True Positive Revenue - Predicted correctly homeowner would take the credit; allocated the marketing resources, and 25% took the credit.
Count*(-2850)-[(Count*.25)*-5000]

False Negative Revenue - We predicted that a homeowner would not take the credit but they did. These are likely homeowners who signed up for reasons unrelated to the marketing campaign. Thus, we ‘0 out’ this category, assuming the cost/benefit of this is $0.
Count*0

False Positive Revenue - Predicted incorrectly homeowner would take the credit; allocated marketing resources; no credit allocated.
Count*-2850

```{r Cost Benfit, message=FALSE, warning=FALSE, , echo=FALSE}

cost_benefit_table <- # Check math
   testProbs2 %>%
      count(predOutcome, observed) %>%
      summarize(True_Negative = sum(n[predOutcome==0 & observed==0]),
                True_Positive = sum(n[predOutcome==1 & observed==1]),
                False_Negative = sum(n[predOutcome==0 & observed==1]),
                False_Positive = sum(n[predOutcome==1 & observed==0])) %>%
       gather(Variable, Count) %>%
       mutate(Revenue =
               case_when(Variable == "True_Negative"  ~ Count * 0,  
                         Variable == "True_Positive"  ~ ((Count * -2850) - ((Count * .25) * -5000)),  
                         Variable == "False_Negative" ~ Count * 0,
                         Variable == "False_Positive" ~ (Count * -2850))) %>%
    bind_cols(data.frame(Description = c(
              "Predicted correctly homeowner would not take the credit, no marketing resources
              were allocated, and no
              credit was allocated.",
              "Predicted correctly homeowner would take the credit; allocated the marketing 
              resources, and 25% took
              the credit.", #25% take the 5000
              "We predicted that a homeowner would not take the credit but they did.",
              "Predicted incorrectly homeowner would take the credit; allocated marketing 
              resources; no credit
              allocated.")))

cost_benefit_table %>%
  kable(caption = "Table 3: Cost/Benefit Table") %>%
  kable_styling()


caret::confusionMatrix(testProbs2$predOutcome, testProbs$observed, 
                       positive = "1")

```

# Optimizing Cost/Benefit Relationship

Ideally, the ‘optimal’ threshold is the one that returns the greatest cost/benefit. In this section, a function is created to iteratively loop through each threshold, calculate confusion metrics, and total the revenue for each. The results are then visualized for each threshold.

```{r Threshold, echo=TRUE, message=FALSE, warning=FALSE}

iterateThresholds.1 <- function(data) {
  x = .01
  all_prediction <- data.frame()
  while (x <= 1) {
  this_prediction <-
      testProbs %>%
      mutate(predOutcome = ifelse(probs > x, 1, 0)) %>%
      count(predOutcome, observed) %>%
      summarize(True_Negative = sum(n[predOutcome==0 & observed==0]),
                True_Positive = sum(n[predOutcome==1 & observed==1]),
                False_Negative = sum(n[predOutcome==0 & observed==1]),
                False_Positive = sum(n[predOutcome==1 & observed==0])) %>%
     gather(Variable, Count) %>%
     mutate(Revenue =
               ifelse(Variable == "True_Negative", Count * 0,
               ifelse(Variable == "True_Positive",((.35 - .1) * Count),
               ifelse(Variable == "False_Negative", (-0.35) * Count,
               ifelse(Variable == "False_Positive", (-0.1) * Count, 0)))),
            Threshold = x)
  all_prediction <- rbind(all_prediction, this_prediction)
  x <- x + .01
  }
return(all_prediction)
}


whichThreshold <- iterateThresholds.1(testProbs2)

whichThreshold %>%
  ggplot(.,aes(Threshold, Revenue, colour = Variable)) +
  geom_point() +
  scale_colour_manual(values = palette4[c(5, 1:3)]) +    
  labs(title = "Figure 9: Revenue by confusion matrix type and threshold",
       y = "Revenue") +
  plotTheme() +
  guides(colour=guide_legend(title = "Confusion Matrix")) 

```


## Plot of Threshold as a Function of Revenue and Count of Credits

This shows thresholds as function of total revenue and count of people who took the credit

```{r Small Multiple Plots, echo=TRUE, message=FALSE, warning=FALSE, fig.height=8}

whichThreshold_revenue <- 
  whichThreshold %>% 
  mutate(TookCredit = ifelse(Variable == "True_Positive", (Count * .25),
                         ifelse(Variable == "False_Negative", Count, 0))) %>%
  group_by(Threshold) %>% 
  summarize(Total_Revenue = sum(Revenue), Total_Count_Of_Credits = sum(TookCredit))

#Plot
grid.arrange(ncol = 1,
             ggplot(whichThreshold_revenue) + 
               geom_line(aes(x = Threshold, y = Total_Revenue)) +
               geom_vline(xintercept =  pull(arrange(whichThreshold_revenue, -Total_Revenue)[1,1])) +
               labs(title = "Figure 10: Total Revenues By Threshold",
                    subtitle = "Vertical Line Denotes Optimal Threshold"),
             ggplot(whichThreshold_revenue) + 
               geom_line(aes(x = Threshold, y = Total_Count_Of_Credits))+
               geom_vline(xintercept =  pull(arrange(whichThreshold_revenue, -Total_Count_Of_Credits)[1,1])) +
               labs(title = "Figure 11: Total Count of Credits By Threshold",
                    subtitle = "Vertical Line Denotes Optimal Threshold"))

whichThreshold_revenue %>%
  kable()%>%
  kable_styling()

```

# Conclusion


